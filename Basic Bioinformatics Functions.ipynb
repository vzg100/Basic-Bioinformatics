{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are common functions used in bioinformatics. Most of these fuctions minimize the use of external libraries. \n",
    "\n",
    "I have included links to solutions that were developed by other individuals. Hopefully this can be of use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sliding Window Approach to counting how many times a substring occurs in the primary string\n",
    "s1 = \"CGCGATACGTTACATACATGATAGACCGCGCGCGATCATATCGCGATTATC\"\n",
    "t1 = \"CGCG\"\n",
    "def sliding_window(s: str, t: str):\n",
    "    c=0\n",
    "    for i in range(len(s)):\n",
    "        if s[i:i+len(t)] == t:\n",
    "            c+=1\n",
    "        else:\n",
    "            pass\n",
    "    return c\n",
    "sliding_window(s1, t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finds Kmers and returns a dict showing frequency of kmers occuring\n",
    "def frequent_words(s: str, k: int):\n",
    "    patterns = {}\n",
    "    for i in range(len(s)):\n",
    "        if len(s[i:i+k]) == k:\n",
    "            if s[i:i+k] in patterns.keys():\n",
    "                patterns[s[i:i+k]] = 1 + patterns[s[i:i+k]]\n",
    "            else:\n",
    "                patterns[s[i:i+k]]=1\n",
    "    return patterns\n",
    "# Finds the most frequent kmers and returns them\n",
    "def most_common(patterns: dict):\n",
    "    highest = []\n",
    "    h = 0\n",
    "    for i in patterns.keys():\n",
    "        if patterns[i] > h:\n",
    "            h = patterns[i]\n",
    "    for i in patterns.keys():\n",
    "        if patterns[i] == h:\n",
    "            highest.append(i)\n",
    "    t = \"\"\n",
    "    for i in highest:\n",
    "        t+=i\n",
    "        t+=\" \"\n",
    "    print(t)\n",
    "    return t.split(\" \")\n",
    "\n",
    "s1 = \"TAAACGTGAGAGAAACGTGCTGATTACACTTGTTCGTGTGGTAT\"\n",
    "k1 = 3\n",
    "most_common(frequent_words(s1, k1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finds the reverse compliment of a sequence containing only ACTG\n",
    "def reverse_compliment(s: str):\n",
    "    nuc = {\"A\":\"T\", \"C\":\"G\", \"T\":\"A\", \"G\":\"C\"}\n",
    "    ns = \"\"\n",
    "    for i in s:\n",
    "        ns+=nuc[i]\n",
    "    ns = ns[::-1]\n",
    "    return ns\n",
    "s1 = \"GCTAGCT\"\n",
    "reverse_compliment(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a simple but very slow solution\n",
    "def match_pattern(s: str, p: str):\n",
    "    spots = []\n",
    "    for i in range(len(s)):\n",
    "        if(s[i:i+len(p)]) == p:\n",
    "            spots.append(i)\n",
    "    return spots\n",
    "s1 = \"ATGACTTCGCTGTTACGCGC\"\n",
    "p1=\"CGC\"\n",
    "\n",
    "print(match_pattern(s1, p1))\n",
    "# Better way is to use regex, must faster however this version doesn't handle overlaps which can miss some spots\n",
    "import re\n",
    "t = [m.start() for m in re.finditer(p1, s1)]\n",
    "print(t)\n",
    "# Best was is using regex with look ahead\n",
    "# Using the folling string modification allows us to \n",
    "p1 = \"(?=\"+p1+\")\"\n",
    "\n",
    "\n",
    "tt = [m.start() for m in re.finditer(p1, s1)]\n",
    "print(tt)\n",
    "\n",
    "\n",
    "# Credits https://stackoverflow.com/questions/4664850/find-all-occurrences-of-a-substring-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def search(s: str, k: int, L: int, t: int):\n",
    "    lookup = defaultdict(list)\n",
    "    result = set()\n",
    "\n",
    "    for pattern in range(len(s) - k + 1):\n",
    "        seg = s[pattern:pattern + k]\n",
    "\n",
    "        # remove prior positions of the same segment\n",
    "        # if they are more than L distance far\n",
    "        while lookup[seg] and pattern + k - lookup[seg][0] > L:\n",
    "            lookup[seg].pop(0)\n",
    "\n",
    "        lookup[seg].append(pattern)\n",
    "        if len(lookup[seg]) == t:\n",
    "            result.add(seg)\n",
    "    return result\n",
    "s1 = \"AAAACGTCGAAAAA\"\n",
    "k = 2\n",
    "L = 4\n",
    "t = 2\n",
    "print(search(s1, k, L, t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converts sequences stored as ints into sequences, k represent the length of the desired sequence\n",
    "def number_to_pattern(n: int, k: int):\n",
    "    t = \"\"\n",
    "    nuc = {\"0\":\"A\", \"1\":\"C\", \"2\":\"G\", \"3\":\"T\"}\n",
    "    for i in range(k):\n",
    "        t+=nuc[str(n%4)]\n",
    "        n = n//4\n",
    "    return t[::-1]\n",
    "\n",
    "print(number_to_pattern(5537, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converts sequence to int\n",
    "def pattern_to_number(s: str):\n",
    "    nuc = {\"A\":0, \"C\":1, \"G\":2, \"T\":3}\n",
    "    p = 0\n",
    "    for i in range(len(s)):\n",
    "        p = p + (nuc[s[i]]*(4**(len(s)-(i+1))))\n",
    "    return p\n",
    "pattern_to_number(\"GGATCTAAGTTAGTTTG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the frequency patterns in a seq, this implementation works on short sequences but has issues on larger sequences  \n",
    "def compute_freq(s: str, k: int):\n",
    "    freq = [0] * (4**k)\n",
    "    for i in range(len(s)-1):\n",
    "        freq[pattern_to_number(s[i:i+k])] = freq[pattern_to_number(s[i:i+k])] + 1\n",
    "    s1 = \"\"\n",
    "    for i in freq:\n",
    "        s1+=str(i)\n",
    "        s1+=\" \"\n",
    "    return s1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def skew(seq: str):\n",
    "    k = 0\n",
    "    s = [0]\n",
    "    nuc = {\"C\":-1, \"A\": 0, \"T\": 0, \"G\": 1}\n",
    "    for i in seq:\n",
    "        s.append(k+nuc[i])\n",
    "        k = k+nuc[i]\n",
    "    return s\n",
    "skew(\"CATGGGCATCGGCCATACGCC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def minimum_skew(seq: str):\n",
    "    skews = skew(seq)\n",
    "    mins = min(skews)\n",
    "    t = [i for i in range(len(skews)) if skews[i] == mins]\n",
    "    print(t)\n",
    "minimum_skew(\"GATACACTTCCCGAGTAGGTACTG\")\n",
    "\n",
    "def max_skew(seq: str):\n",
    "    skews = skew(seq)\n",
    "    maxs = max(skews)\n",
    "    return [i for i in range(len(skews)) if skews[i] == maxs]\n",
    "#max_skew(\"CATTCCAGTACTTCATGATGGCGTGAAGA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hamming_distance(seq1: str, seq2: str):\n",
    "    #https://pythonadventures.wordpress.com/2010/10/19/hamming-distance/\n",
    "    if len(seq1) == len(seq2):\n",
    "        return int(sum(ch1 != ch2 for ch1, ch2 in zip(seq1, seq2)))\n",
    "    else:\n",
    "        return -1\n",
    "        \n",
    "s1 = \"TGACCCGTTATGCTCGAGTTCGGTCAGAGCGTCATTGCGAGTAGTCGTTTGCTTTCTCAAACTCC\"\n",
    "s2 = \"GAGCGATTAAGCGTGACAGCCCCAGGGAACCCACAAAACGTGATCGCAGTCCATCCGATCATACA\"\n",
    "hamming_distance(s1, s2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pattern_occurences(seq: str, pattern: str, hamming: int):\n",
    "    c = []\n",
    "    for i in range(0,len(seq)):\n",
    "        t = hamming_distance(seq[i:i+len(pattern)], pattern) \n",
    "        if t <= hamming and t != -1:\n",
    "            c.append(i)\n",
    "    return c\n",
    "    \n",
    "s = \"CGCCCGAATCCAGAACGCATTCCCATATTTCGGGACCACTGGCCTCCACGGTACGGACGTCAATCAAAT\"\n",
    "p = \"ATTCTGGA\"\n",
    "h = 3\n",
    "pattern_occurences(s,p,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def mutations(word, hamming_distance, charset='ATCG'):\n",
    "    # https://stackoverflow.com/questions/19941079/inverse-of-hamming-distance\n",
    "    for indices in itertools.combinations(range(len(word)), hamming_distance):\n",
    "        for replacements in itertools.product(charset, repeat=hamming_distance):\n",
    "            mutation = list(word)\n",
    "            for index, replacement in zip(indices, replacements):\n",
    "                mutation[index] = replacement\n",
    "            yield \"\".join(mutation)\n",
    "\n",
    "def count(seq: str, pattern: str, h: int):\n",
    "    c = 0\n",
    "    for i in set(mutations(pattern, h)):\n",
    "        pattern = \"(?=\"+pattern+\")\"\n",
    "        c+=len([m.start() for m in re.finditer(i, seq)])\n",
    "    return c\n",
    "\n",
    "s = \"TACGCATTACAAAGCACA\"\n",
    "p = \"AA\"\n",
    "h = 1\n",
    "count(s, p, h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neighbors(s, h):\n",
    "    c = []\n",
    "    for i in set(mutations(s, h)):\n",
    "        c.append(i)\n",
    "    print(len(c))\n",
    "neighbors(\"TGCAT\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def kmers_finder_with_mismatches(seq: str, k: int, h: int, most_common=False):\n",
    "    # https://gist.github.com/alec-djinn/9018370\n",
    "    motif_dict = {}\n",
    "    for i in range(len(sequence) - motif_length +1):\n",
    "        motif = sequence[i:i+motif_length]\n",
    "        if motif not in motif_dict:\n",
    "            motif_dict[motif] = 1\n",
    "        else:\n",
    "            motif_dict[motif] += 1\n",
    "    #check for mismatches\n",
    "    motif_dict_with_mismatches = {}\n",
    "    for kmer in motif_dict:\n",
    "        motif_dict_with_mismatches.update({kmer:[]})\n",
    "            \n",
    "        for other_kmer in motif_dict:\n",
    "            mismatches = 0\n",
    "            for i in range(len(kmer)):\n",
    "                if kmer[i] != other_kmer[i]:\n",
    "                    mismatches += 1\n",
    "            if mismatches <= max_mismatches:\n",
    "                motif_dict_with_mismatches[kmer].append([other_kmer,motif_dict[other_kmer]])\n",
    "    #count occurrences of motifs\n",
    "    tmp = {}\n",
    "    for item in motif_dict_with_mismatches:\n",
    "        count = 0\n",
    "        for motif in motif_dict_with_mismatches[item]:\n",
    "            count += motif[-1]\n",
    "        tmp.update({item:count})\n",
    "\n",
    "    result = OrderedDict(sorted(tmp.items(), key=itemgetter(1), reverse=True))\n",
    "    #find the most common/s\n",
    "    if most_common:\n",
    "        commons = OrderedDict()\n",
    "        _max = result.items()[0][1]\n",
    "        for item in result:\n",
    "            if result[item] == _max:\n",
    "                commons.update({item:result[item]})\n",
    "            else:\n",
    "                return commons\n",
    "    return result\n",
    "\n",
    "sequence = 'ACGTTGCATGTCGCATGATGCATGAGAGCT'\n",
    "\n",
    "motif_length = 4\n",
    "max_mismatches = 1\n",
    "a = kmers_finder_with_mismatches(sequence, motif_length, max_mismatches, most_common=False)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/45802748/dna-motif-enumeration-with-try-except-and-loops-python3\n",
    "# This stack overflow posts shows some really powerfull ways to solve basic problems using some python optimizations\n",
    "def combination(k):\n",
    "    return (''.join(p) for p in itertools.product('ATCG', repeat=k))\n",
    "\n",
    "def hamming_distance(pattern, seq):\n",
    "    return sum(c1 != c2 for c1, c2 in zip(pattern, seq))\n",
    "\n",
    "def window(s, k):\n",
    "    for i in range(1 + len(s) - k):\n",
    "        yield s[i:i+k]\n",
    "\n",
    "def motif_enumeration(seq: str, k: int, d: int):\n",
    "    pattern = set()\n",
    "    for combo in combination(k):\n",
    "        if all(any(hamming_distance(combo, pat) <= d \n",
    "                for pat in window(string, k)) for string in seq):\n",
    "            pattern.add(combo)\n",
    "    return pattern\n",
    "            \n",
    "        \n",
    "s =[\"AAGAAGCTTAGCCATTCGAAACACC\", \"GAGCGGTTGCGGCATGAAATTTTCA\", \"CCTAAGCCATCATCCAGTTCAATGA\", \"AGGTTGAACGGGATTGCCATATGCT\", \"TGTCTTCCCTATTTTGCCGCGACAT\", \"GGAAAGCCTAGTCATGCTCAATCGA\"]\n",
    "k = 5\n",
    "d = 1\n",
    "motif_enumeration(s, k, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/jarecot/Rosalind/blob/master/Textbook_03B.py\n",
    "from itertools import product\n",
    "def median_string(k: int, seqs: list):\n",
    "    best_score = k*len(seqs) + 1\n",
    "    for pattern in product('ACGT', repeat=k):\n",
    "        current_score = sum([motif_score(''.join(pattern), seq) for seq in seqs])\n",
    "        if current_score < best_score:\n",
    "            best_score = current_score\n",
    "            best_pattern = ''.join(pattern)\n",
    "    return best_pattern\n",
    "\n",
    "def motif_score(pattern, motif):\n",
    "    return min([hamming_distance(motif[i:i+len(pattern)], pattern) for i in range(len(motif)-len(pattern)+1)])\n",
    "seqs = [\"CTCGATGAGTAGGAAAGTAGTTTCACTGGGCGAACCACCCCGGCGCTAATCCTAGTGCCC\", \"GCAATCCTACCCGAGGCCACATATCAGTAGGAACTAGAACCACCACGGGTGGCTAGTTTC\",\"GGTGTTGAACCACGGGGTTAGTTTCATCTATTGTAGGAATCGGCTTCAAATCCTACACAG\"]\n",
    "k = 7\n",
    "median_string(k, seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import mul\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "#https://github.com/minw2828/Coursera---Bioinformatics-Algorithms/blob/master/chapter3/C3_39/39_3/pmpkp.py\n",
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "s = \"ACCTGTTTATTGCCTAAGTTCCGAACAAACCCAATATAGCCCGAGGGCCT\"\n",
    "k = 5\n",
    "p = [[.2, .2, .3, .2, .3], [.4, .3, .1, .5, .1], [.3, .3, .5, .2, .4], [.1, .2, .1, .1, .2]]\n",
    "def find_kmers(seq, k):\n",
    "    return set(seq[i:i+k] for i in range(len(seq)-k+1))\n",
    "\n",
    "def calculate(kmer, profile, order={\"A\":0, \"C\":1, \"G\":2, \"T\":3}):\n",
    "    c = []\n",
    "    for i in range(0, len(kmer)):\n",
    "        c.append(profile[order[kmer[i]]][i])\n",
    "    return reduce(operator.mul, c, 1)\n",
    "    \n",
    "\n",
    "def profile(seq, k, profile):\n",
    "    results = [(kmer, calculate(kmer,profile)) for kmer in find_kmers(seq, k)]\n",
    "    return sorted(results,key=lambda x:x[1],reverse=True)[0][0]\n",
    "profile(s, k, p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sys import maxsize\n",
    "def distanceBetweenPatternAndStrings(p, seq): \n",
    "    k = len(p) \n",
    "    distance = 0\n",
    "    for s in  seq:\n",
    "        hd = maxsize \n",
    "        for i in range(0, len(s)-k+1): \n",
    "            if hd > hamming_distance(p, s[i:i+k]): \n",
    "                hd = hamming_distance(p, s[i:i+k]) \n",
    "        distance = distance + hd\n",
    "    return distance\n",
    "p = \"AAA\"\n",
    "s = [i for i in \"TTACCTTAAC GATATCTGTC ACGGCGTTCG CCCTAAAGAG CGTCAGAGGT\".split(\" \")]\n",
    "distanceBetweenPatternAndStrings(p, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find the Mass of a Protien using monoisotopic Mass\n",
    "prot_mass = {\n",
    "    \"A\":71.03711, \"C\":103.00919, \"D\":115.02694, \"E\":129.04259, \"F\":147.06841, \"G\":57.02146, \"H\":137.05891, \n",
    "    \"I\":113.08406, \"K\":128.09496, \"L\":113.08406, \"M\":131.04049, \"N\":114.04293, \"P\":97.05276, \"Q\":128.05858,\n",
    "    \"R\":156.10111, \"S\": 87.03203, \"T\":101.04768, \"V\": 99.06841, \"W\":186.07931, \"Y\":163.06333\n",
    "}\n",
    "s = \"SKADYEK\"\n",
    "mass = 0\n",
    "for i in s:\n",
    "    mass += prot_mass[i]\n",
    "print(mass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict Dominant Allele is in two organisms randomly selected from pop - Rosalind Mendels First Law\n",
    "from scipy.misc import comb\n",
    "hom = 27\n",
    "het = 23\n",
    "rec = 27\n",
    "total = 4*comb(hom+het+rec, 2)\n",
    "total_rec = 4*comb(rec, 2) + 2*rec*het + comb(het,2)\n",
    "x = 1- (total_rec/total)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculating Expected Dominant displaying Offspring from population\n",
    "file = open('Path','r')\n",
    "pop = [float(x) for x in file.readline().split()]\n",
    "multiplier = [1.0,1.0,1.0,0.75,0.5,0]\n",
    "\n",
    "exp = 0\n",
    "for x in range(6):\n",
    "    exp = exp + 2* pop[x]*multiplier[x]\n",
    "print(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rosalind find a shared motif\n",
    "from Bio import SeqIO\n",
    "def shared_motif(file):\n",
    "    f = open(file, \"r\")\n",
    "    motif = \"\"\n",
    "    #Really Dense line of code\n",
    "    #Opens Fasta, extracts seq and adds to array, sorts array by length with shortest first\n",
    "    seqs = sorted([line.seq for line in SeqIO.parse(f, \"fasta\")], key=len)\n",
    "    short, the_rest = seqs[0], seqs[1:]\n",
    "    for i in range(len(short)):\n",
    "        for j in range(i, len(short)):\n",
    "            temp_motif = short[i:j+1]\n",
    "            counter = 0\n",
    "            for long_seq in the_rest:\n",
    "                if temp_motif in long_seq:\n",
    "                    counter+=1\n",
    "                else:\n",
    "                    break #Break cuts down runtime alot\n",
    "            if counter == len(the_rest) and len(temp_motif) > len(motif):\n",
    "                motif = temp_motif \n",
    "    print(motif)\n",
    "    return motif\n",
    "                \n",
    "            \n",
    "            \n",
    "shared_motif(\"Path\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rosalind Mortal Fib Rabbits, rosalind solution -- https://duphan.wordpress.com/2015/07/10/dynamic-programming-and-mortal-fibonacci-rabbits/\n",
    "def rabbits(n, k=1):\n",
    "    ages = [1] + [0]*(k-1)\n",
    "    for i in range(n-1):\n",
    "        ages = [sum(ages[1:])] + ages[:-1]\n",
    "    return sum(ages)\n",
    "rabbits(6, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rosalind Inferring mRNA from protien\n",
    "\n",
    "def prot_to_mrna(seq):\n",
    "    aa_count = {\n",
    "        \"F\":2, \"L\":6, \"I\":3, \"M\":1, \"V\":4, \"A\":4, \"T\":4, \"P\":4, \"S\":6, \"Y\":2, \"stop\":3, \"H\":2, \"Q\":2, \"N\":2, \"K\":2, \n",
    "        \"D\":2, \"E\":2, \"C\":2, \"W\":1, \"R\":6, \"G\":4}\n",
    "    count = 1\n",
    "    for i in seq:\n",
    "        count *= aa_count[i]\n",
    "    count*=3\n",
    "    count%= 1000000\n",
    "    return count\n",
    "\n",
    "x=\"MA\"\n",
    "prot_to_mrna(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rosalind Mendels Second Law\n",
    "#Assume starting Pop is AaBb, each child has 2 children, each one mates with AaBb pop memeber\n",
    "#Find prob that at least n organisms will belong in family at k'th genertion\n",
    "import math\n",
    "def mendels_second_law(k, N):                                                    \n",
    "    P = 2**k                                                                       \n",
    "    probability = 0                                                                \n",
    "    for i in range(N, P + 1):                                                      \n",
    "        prob = (math.factorial(P) /                                                \n",
    "                (math.factorial(i) * math.factorial(P - i))) * (0.25**i) * (0.75**(\n",
    "                    P - i))                                                        \n",
    "        probability += prob                                                        \n",
    "    return probability\n",
    "mendels_second_law(5, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rosalind Consensus Profile\n",
    "import operator\n",
    "from Bio import SeqIO\n",
    "def profile(file):\n",
    "    f = open(file)\n",
    "    seqs = sorted([line.seq for line in SeqIO.parse(f, \"fasta\")], key=len)\n",
    "    prof = [[0 for i in range(len(seqs[-1]))] for i in range(4)]\n",
    "\n",
    "    for s in seqs:\n",
    "        for i in range(len(s)):\n",
    "            if s[i] == \"A\":\n",
    "                prof[0][i] +=1\n",
    "            if s[i] == \"C\":\n",
    "                prof[1][i] +=1\n",
    "            if s[i] == \"G\":\n",
    "                prof[2][i] +=1\n",
    "            if s[i] == \"T\":\n",
    "                prof[3][i] +=1\n",
    "    profile = {\"A\":prof[0], \"C\":prof[1],  \"G\":prof[2],\"T\":prof[3]}\n",
    "    for i in \"ACGT\":\n",
    "        t = \"\"\n",
    "        for j in profile[i]:\n",
    "            t += str(j)\n",
    "            t+= \" \"\n",
    "        print(i+\":\", t)\n",
    "    return profile\n",
    "\n",
    "def consensus(prof: dict):\n",
    "    s = \"\"\n",
    "    for i in range(len(prof[\"A\"])):\n",
    "        t = {\"A\":prof[\"A\"][i], \"C\":prof[\"C\"][i], \"T\":prof[\"T\"][i], \"G\":prof[\"G\"][i], }\n",
    "        s+= max(t, key=lambda key: t[key])\n",
    "    return s\n",
    "\n",
    "print(consensus(profile(\"file\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rosalind Random Strings\n",
    "import math\n",
    "AT = 0\n",
    "GC = 0\n",
    "def random_string(file):\n",
    "    f = open(file, \"r\")\n",
    "    AT=0\n",
    "    GC=0\n",
    "    for line in f:\n",
    "        if \"A\" not in line:\n",
    "            numbers = line.split()\n",
    "            GC_contents = [float(x) for x in numbers]\n",
    "        for i in line:\n",
    "            if i == 'A' or i == 'T':\n",
    "                AT += 1\n",
    "            elif i == 'G' or i == 'C':\n",
    "                GC += 1\n",
    "    probs = []\n",
    "    for j in range(len(GC_contents)):\n",
    "        prob = math.log10((((1 - GC_contents[j]) / 2)**AT) * (GC_contents[j] / 2)\n",
    "                          **GC)\n",
    "        probs.append('%0.3f' % prob) #Neat trick need to look into more \n",
    "    print(*probs, sep=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_bases(seq):\n",
    "    counter = {}\n",
    "    for i in seq:\n",
    "        if i not in counter.keys():\n",
    "            counter[i] = 1\n",
    "        else:\n",
    "            counter[i] +=1\n",
    "    return counter\n",
    "count_bases(\"AGCTTTTCATTCTGACTGCAACGGGCAATATGTCTCTGTGTGGATTAAAAAAAGAGTGTCTGATAGCAGC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purine ribonucleoside salvage\n",
      "XMP salvage\n"
     ]
    }
   ],
   "source": [
    "from Bio import ExPASy\n",
    "from Bio import SwissProt\n",
    "def prot_func(prot_id):\n",
    "    handle = ExPASy.get_sprot_raw(prot_id)\n",
    "    record = SwissProt.read(handle)\n",
    "    for i in record.cross_references:\n",
    "        if (i[0] == 'GO'):\n",
    "            if (i[2][0] == 'P'):\n",
    "                print(i[2][2:])\n",
    "    \n",
    "prot_func(\"Q0T7Q9\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535\n"
     ]
    }
   ],
   "source": [
    "#Rosalind GenBank Intro\n",
    "from Bio import Entrez\n",
    "def gene_bank_intro(email=\"\", genus=\"Bufo\", dates=[\"2002/09/07\",\"2011/07/18\"]):\n",
    "    Entrez.email = email\n",
    "    term = '%s[Organism] AND (\"%s\"[PDAT] : \"%s\"[PDAT])' % (genus, dates[0], dates[1])\n",
    "    handle = Entrez.esearch(db=\"nucleotide\", term=term)\n",
    "    record = Entrez.read(handle)\n",
    "    print(record[\"Count\"])\n",
    "gene_bank_intro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46368\n"
     ]
    }
   ],
   "source": [
    "#Simple Fib number calc, not optimal solution\n",
    "def fib_num(a=0, b=1, c=24):\n",
    "    if c != 0:\n",
    "        fib_num(a=b, b=a+b, c=c-1)\n",
    "    else:\n",
    "        print(a)\n",
    "        return a\n",
    "fib_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> JX462669.1 Belgica antarctica ribosomal protein 49 (rp49) mRNA, complete cds\n",
      "ATGGCAGTTCGACCAGCATTCAAACCCAAAATCATCAAAAAGAGAACGAAGAAGTTCATCCGCCATCAGTCGGACCGATATGACAAAGTCAAGGAAGCTTGGCGCAAGCCCAAGGGTATTGACAACAGAGTCAGACGTCGCTTTAAGGGACAGTACCTGATGCCAAACATCGGCTACGGTTCCAACGCCAAGACCCGCCACATGCTCCCCAACGGCTTCAAGAAGTTCACCGTCAACAACGTCCGCGAGTTGGAGGTCTTGATGATGCAAAACCGCGTTTACTGCGCCGAGGTCGCTCACGCCGTCAGCGCCAAGAAGCGTAAGCTGATCTGCGAACGTGCTAAGCAGCTGGGAATCCGTGTGACCAACTTCCACGCAAGAATGCGATCACAGGAAAATGAGTAA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SeqRecord(seq=Seq('ATGGCAGTTCGACCAGCATTCAAACCCAAAATCATCAAAAAGAGAACGAAGAAG...TAA', SingleLetterAlphabet()), id='JX462669.1', name='JX462669.1', description='JX462669.1 Belgica antarctica ribosomal protein 49 (rp49) mRNA, complete cds', dbxrefs=[]),\n",
       " SeqRecord(seq=Seq('CGGCGGCCTCAGACTCCTTGGGTATTTGGACCACTGCACCGAAGATACCATCTC...AAA', SingleLetterAlphabet()), id='NM_013179.2', name='NM_013179.2', description='NM_013179.2 Rattus norvegicus hypocretin neuropeptide precursor (Hcrt), mRNA', dbxrefs=[]),\n",
       " SeqRecord(seq=Seq('ATGAAGTGCACCATTTTATTGAGTTTTTTCAGCCTGATTTGGTTTGCTGGTGGA...TGA', SingleLetterAlphabet()), id='BT149870.1', name='BT149870.1', description='BT149870.1 Drosophila melanogaster RT12737 full insert cDNA', dbxrefs=[]),\n",
       " SeqRecord(seq=Seq('ATGGCGGAACTTGTACAATCATCTCCCATTTCCGTGTCAAAAACAGAGGAACCA...TGA', SingleLetterAlphabet()), id='JX428803.1', name='JX428803.1', description='JX428803.1 Solanum tuberosum AP2 c4 mRNA, complete cds', dbxrefs=[]),\n",
       " SeqRecord(seq=Seq('AGGATTGAGAACAAGATCAATAGGCAAGTGACTTTTTCAAAGAGAAGGTCTGGT...TAG', SingleLetterAlphabet()), id='JX308821.1', name='JX308821.1', description='JX308821.1 Medicago ruthenica FRUITFULLb mRNA, partial cds', dbxrefs=[]),\n",
       " SeqRecord(seq=Seq('ATGATGCTGAGCGGGCACGGCGGCGGGAGGCGCCTGTTCACGGCGTCGCAGTGG...TCC', SingleLetterAlphabet()), id='JX469985.1', name='JX469985.1', description='JX469985.1 Zea mays subsp. mays clone UT3345 GRF-type transcription factor mRNA, partial cds', dbxrefs=[]),\n",
       " SeqRecord(seq=Seq('CGCGTATTTCGTTTGAGCCAATACCAAGTAGACAGAACCAACAAATTCGACACC...AAA', SingleLetterAlphabet()), id='FJ817486.1', name='FJ817486.1', description='FJ817486.1 Malus hybrid cultivar flavanone 3-hydroxylase protein (F3H) mRNA, complete cds', dbxrefs=[]),\n",
       " SeqRecord(seq=Seq('CAGACCCTTTTTGTCTCTCGATTGCTGTCTCCCGACCAAACTCCGATGTGTTCC...AAA', SingleLetterAlphabet()), id='NM_204821.1', name='NM_204821.1', description='NM_204821.1 Gallus gallus sonic hedgehog (SHH), mRNA', dbxrefs=[]),\n",
       " SeqRecord(seq=Seq('ACATGGGAAGCAGTGGGACGAGCAGAGTAGTCAAAGACTCAACTAAGCTTCATC...AAA', SingleLetterAlphabet()), id='JX445144.3', name='JX445144.3', description='JX445144.3 Paeonia lactiflora cultivar Taohuafeixue ethylene-insensitive 3 (EIN3) mRNA, complete cds', dbxrefs=[])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rosalind Data Formats\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "def gene_bank_intro(email=\"\", file=\"\"):\n",
    "    f = open(file, \"r\")\n",
    "    names = [i.split(\" \") for i in f][0]\n",
    "    f.close()\n",
    "    Entrez.email = email\n",
    "    handle = Entrez.efetch(db=\"nucleotide\", id=names, rettype=\"fasta\")\n",
    "    records = list(SeqIO.parse(handle, \"fasta\"))\n",
    "    ordered = sorted(records, key=len)\n",
    "\n",
    "    print(\">\",ordered[0].description)\n",
    "    print(ordered[0].seq)\n",
    "    return ordered\n",
    "gene_bank_intro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rosalind Fastaq-> fasta\n",
    "from Bio import SeqIO\n",
    "def fastaq_to_fasta(file=\"\", out_put=\"\"):\n",
    "    with open(file, \"r\") as handle:\n",
    "        sequences = SeqIO.parse(handle, \"fastq\")\n",
    "        count = SeqIO.write(sequences, out_put, \"fasta\")\n",
    "    \n",
    "fastaq_to_fasta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVYIADKQHVASREAYGHMFKVCA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq('MVYIADKQHVASREAYGHMFKVCA', ExtendedIUPACProtein())"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rosalind SPLCfinding exons and translating them\n",
    "from Bio.Seq import Seq\n",
    "def find_exons_translate(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        seqs =[str(seq.seq) for seq in SeqIO.parse(f, 'fasta')]\n",
    "        master_seq = seqs[0]\n",
    "        introns = seqs[1:]\n",
    "        for i in introns:\n",
    "            master_seq = master_seq.replace(i, \"\")\n",
    "        s = Seq(master_seq).translate(to_stop=True)\n",
    "        print(s)\n",
    "        return s\n",
    "        \n",
    "find_exons_translate(\"/Users/mark/Downloads/ros.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "MVYIADKQHVASREAYGHMFKVCA\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer(data, n):\n",
    "    # your code here\n",
    "    return [i for i in data if data.count(i) <= n]\n",
    "            \n",
    "    \n",
    "answer([1,1,2,3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1211 % 10\n",
    "(2111 - 1112) % 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
